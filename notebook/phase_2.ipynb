{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdbe4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['CUB', 'Derm7pt', 'RIVAL10']\n",
    "use_dataset = datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c415bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root_path = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, project_root_path)\n",
    "\n",
    "from src.config import CUB_CONFIG, DERM7PT_CONFIG, RIVAL10_CONFIG\n",
    "from src.config import PROJECT_ROOT\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc4dd3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_dataset == 'CUB':\n",
    "    config_dict = CUB_CONFIG\n",
    "    DATASET_PATH =  os.path.join(PROJECT_ROOT, 'output', 'CUB')\n",
    "elif use_dataset == 'Derm7pt':\n",
    "    config_dict = DERM7PT_CONFIG\n",
    "    DATASET_PATH =  os.path.join(PROJECT_ROOT, 'output', 'Derm7pt')\n",
    "else:\n",
    "    config_dict = RIVAL10_CONFIG\n",
    "    DATASET_PATH =  os.path.join(PROJECT_ROOT, 'output', 'RIVAL10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4b59a",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc1bbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANCE-BASED CUB MODEL\n",
    "\n",
    "# C_train = np.load(os.path.join(PROJECT_ROOT, 'output', 'CUB', 'C_train_instance.npy'))\n",
    "# C_hat_train = np.load(os.path.join(PROJECT_ROOT, 'output', 'CUB', 'C_hat_sigmoid_train_instance.npy'))\n",
    "# one_hot_Y_train = np.load(os.path.join(PROJECT_ROOT, 'output', 'CUB', 'Y_train_instance.npy'))\n",
    "\n",
    "# C_test = np.load(os.path.join(PROJECT_ROOT, 'output', 'CUB', 'C_test_instance.npy'))\n",
    "# C_hat_test = np.load(os.path.join(PROJECT_ROOT, 'output', 'CUB', 'C_hat_sigmoid_test_instance.npy'))\n",
    "# one_hot_Y_test = np.load(os.path.join(PROJECT_ROOT, 'output', 'CUB', 'Y_test_instance.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b037fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_hat_train = np.load(os.path.join(DATASET_PATH, 'C_hat_sigmoid_train.npy'))\n",
    "one_hot_Y_train = np.load(os.path.join(DATASET_PATH, 'Y_train.npy'))\n",
    "\n",
    "C_hat_test = np.load(os.path.join(DATASET_PATH, 'C_hat_sigmoid_test.npy'))\n",
    "one_hot_Y_test = np.load(os.path.join(DATASET_PATH, 'Y_test.npy'))\n",
    "\n",
    "if use_dataset == 'Derm7pt':\n",
    "    C_hat_val = np.load(os.path.join(DATASET_PATH, 'C_hat_sigmoid_val.npy'))\n",
    "    one_hot_Y_val = np.load(os.path.join(DATASET_PATH, 'Y_val.npy'))\n",
    "\n",
    "class_level_concepts = np.load(os.path.join(DATASET_PATH, 'class_level_concepts.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc3226bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.argmax(one_hot_Y_train, axis=1)\n",
    "Y_test = np.argmax(one_hot_Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85ad0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_train = []\n",
    "for y in Y_train:\n",
    "    C_train.append(class_level_concepts[y])\n",
    "\n",
    "C_train = np.array(C_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47193d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# C_hat_train, C_train, one_hot_Y_train, Y_train = shuffle(C_hat_train, C_train, one_hot_Y_train, Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab9f675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_hat_train.shape, one_hot_Y_train.shape, C_hat_test.shape, one_hot_Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6054b78b-b816-4763-87ff-35034efd2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_hat_train[C_hat_train < 0.1] = 0\n",
    "# C_hat_test[C_hat_test < 0.1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99f9c0",
   "metadata": {},
   "source": [
    "# Classic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424779b",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a6ed058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test accuracy: 0.9568671963677639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(C_hat_train, Y_train)\n",
    "print(f\"Logistic Regression Test accuracy: {model.score(C_hat_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e627c",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ec9af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Test accuracy: 0.9559213015512675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(C_hat_train, Y_train)\n",
    "print(f\"k-NN Test accuracy: {model.score(C_hat_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14b904",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e8610c3-c78b-4997-9055-10af7ccf5958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Test accuracy: 0.9453272796065078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(C_hat_train, Y_train)\n",
    "print(f\"Decision Tree Test accuracy: {model.score(C_hat_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff22cb",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f9c3248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test accuracy: 0.9517593643586834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512,256, 128), max_iter=1000)\n",
    "mlp.fit(C_hat_train, Y_train)\n",
    "print(f\"MLP Test accuracy: {mlp.score(C_hat_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5950cfd",
   "metadata": {},
   "source": [
    "# Accuracy Using Class-Level Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5a37c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy using concept-based nearest neighbor: 0.9565\n"
     ]
    }
   ],
   "source": [
    "# Function to find the closest concept vector and predict the label\n",
    "def predict_nearest_concept(instance, reference_concepts, reference_labels):\n",
    "    distances = np.sqrt(np.sum((reference_concepts - instance)**2, axis=1))\n",
    "    min_idx = np.argmin(distances)\n",
    "    return reference_labels[min_idx]\n",
    "\n",
    "# Use C_train as reference concepts and evaluate on C_hat_test\n",
    "correct_predictions = 0\n",
    "total_predictions = len(C_hat_test)\n",
    "\n",
    "for i, test_instance in enumerate(C_hat_test):\n",
    "    predicted_label = predict_nearest_concept(test_instance, C_train, Y_train)\n",
    "    true_label = Y_test[i]\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"\\nOverall accuracy using concept-based nearest neighbor: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9dc649-e4d0-40d5-aa23-bd8b5360bea6",
   "metadata": {},
   "source": [
    "# Prototype-Based Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6be3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "118ea801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da7dda",
   "metadata": {},
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "482ea172",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split_ratio = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "C_hat_train, C_hat_val, Y_train, Y_val = train_test_split(C_hat_train, one_hot_Y_train, test_size=val_split_ratio, random_state=random_seed)\n",
    "\n",
    "X_train = torch.tensor(C_hat_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(C_hat_val, dtype=torch.float32)\n",
    "Y_val = torch.tensor(Y_val, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(C_hat_test, dtype=torch.float32, device=device)\n",
    "Y_test = torch.tensor(one_hot_Y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a8c4e",
   "metadata": {},
   "source": [
    "## Learn Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb8f8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import PrototypeClassifier\n",
    "\n",
    "num_concepts = config_dict['N_TRIMMED_CONCEPTS']\n",
    "num_classes = config_dict['N_CLASSES']\n",
    "\n",
    "model = PrototypeClassifier(num_concepts, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lambda_binary = 0.01\n",
    "lambda_L1 = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7f50626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200]\n",
      "Train Loss: 2.7609, Train Accuracy: 95.66%, Validation Accuracy: 95.81%\n",
      "Epoch [20/200]\n",
      "Train Loss: 0.9579, Train Accuracy: 95.73%, Validation Accuracy: 95.92%\n",
      "Epoch [30/200]\n",
      "Train Loss: 0.5516, Train Accuracy: 95.76%, Validation Accuracy: 95.90%\n",
      "Epoch [40/200]\n",
      "Train Loss: 0.4432, Train Accuracy: 95.76%, Validation Accuracy: 95.90%\n",
      "Epoch [50/200]\n",
      "Train Loss: 0.4147, Train Accuracy: 95.75%, Validation Accuracy: 95.90%\n",
      "Epoch [60/200]\n",
      "Train Loss: 0.4078, Train Accuracy: 95.75%, Validation Accuracy: 95.90%\n",
      "Epoch [70/200]\n",
      "Train Loss: 0.4070, Train Accuracy: 95.75%, Validation Accuracy: 95.90%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 7\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_L1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m val_epoch(model, val_loader, device)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m((epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/career/lab_ujm/hybrid-cbm-prototype-model/src/training/prototype_training.py:35\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, optimizer, lambda_binary, lambda_L1, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# back propagation\u001b[39;00m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# accumulative training loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and test\n",
    "from src.training import train_epoch, val_epoch\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train_epoch(model, train_loader, optimizer, lambda_binary, lambda_L1, device=device)\n",
    "    val_accuracy = val_epoch(model, val_loader, device)\n",
    "    if((epoch+1)%10==0):\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b82dc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9564888384411654"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels = Y_test.argmax(dim=1)\n",
    "predictions = model.predict(X_test)\n",
    "(predictions == real_labels).sum().item()/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b09a36",
   "metadata": {},
   "source": [
    "# MY OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ade5c6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8035714626312256% of the values are close to 0 or 1\n"
     ]
    }
   ],
   "source": [
    "close_to_zero = (torch.sum((model.get_sigmoid_prototypes() < 0.1) | (model.get_sigmoid_prototypes() > 0.9)) / (200*112)).cpu().numpy()\n",
    "print(f\"{close_to_zero*100}% of the values are close to 0 or 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfe9091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Plotting ---\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# epochs_range = range(1, epochs + 1)\n",
    "# plt.plot(epochs_range, train_losses, label='Training Loss', marker='o', linestyle='-')\n",
    "# plt.plot(epochs_range, val_losses, label='Validation Loss', marker='x', linestyle='--')\n",
    "# plt.title('Training and Validation Loss Over Epochs')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Average Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Optional: Plot validation accuracy as well\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(epochs_range, val_accuracies, label='Validation Accuracy', marker='s', linestyle='-', color='green')\n",
    "# plt.title('Validation Accuracy Over Epochs')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a987f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prototypes = []\n",
    "# for y in Y_train:\n",
    "#     prototypes.append(final_binary_prototypes[y])\n",
    "\n",
    "# prototypes = np.array(prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "daad5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to find the closest concept vector and predict the label\n",
    "# def predict_nearest_concept(instance, reference_concepts, reference_labels):\n",
    "#     distances = np.sum(np.abs(reference_concepts - instance), axis=1)\n",
    "#     min_idx = np.argmin(distances)\n",
    "#     return reference_labels[min_idx]\n",
    "\n",
    "# # Use prototypes as reference concepts and evaluate on C_hat_test\n",
    "# correct_predictions = 0\n",
    "# total_predictions = len(C_hat_test)\n",
    "\n",
    "# for i, test_instance in enumerate(C_hat_test):\n",
    "#     predicted_label = predict_nearest_concept(test_instance, prototypes, Y_train)\n",
    "#     true_label = Y_test[i]\n",
    "\n",
    "#     if predicted_label == true_label:\n",
    "#         correct_predictions += 1\n",
    "\n",
    "# # Calculate and print accuracy\n",
    "# accuracy = correct_predictions / total_predictions\n",
    "# print(f\"\\nOverall accuracy using prototype-based nearest neighbor: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666fb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
