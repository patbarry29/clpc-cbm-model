{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64468ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root_path = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, project_root_path)\n",
    "\n",
    "from src.preprocessing.CUB import preprocessing_CUB\n",
    "from src.utils import *\n",
    "from src.config import PROJECT_ROOT\n",
    "from src.training import run_epoch_x_to_c\n",
    "\n",
    "from src.utils import find_class_imbalance\n",
    "from src.config import CUB_CONFIG\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c60c4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIMMED_CONCEPTS = CUB_CONFIG['N_TRIMMED_CONCEPTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f39434-7c40-43b6-bde9-193b7f3b4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bff13a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11788 images.\n",
      "Processing in 185 batches of size 64 (for progress reporting)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|█████████████████████| 185/185 [01:01<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished processing.\n",
      "Successfully transformed: 11788 images.\n",
      "Found 11788 unique images.\n",
      "Found 312 unique concepts.\n",
      "Generated concept matrix with shape: (11788, 312)\n",
      "Found 200 classes.\n",
      "Found labels for 11788 images.\n",
      "Generated one-hot matrix with shape: (11788, 200)\n",
      "Split complete: 5994 train images, 5794 test images.\n",
      "Dataset initialized with 5994 pre-sorted items.\n",
      "Dataset initialized with 5794 pre-sorted items.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "concept_labels, train_loader, test_loader = preprocessing_CUB(training=False, class_concepts=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2cf9e",
   "metadata": {},
   "source": [
    "**Find device to run model on (CPU or GPU).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5893fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                    else \"mps\" if torch.backends.mps.is_available()\n",
    "                    else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc3f7e",
   "metadata": {},
   "source": [
    "### Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f33d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_weighted_loss = True # Set to False for simple unweighted loss\n",
    "\n",
    "if use_weighted_loss:\n",
    "    concept_weights = find_class_imbalance(concept_labels)\n",
    "    attr_criterion = [nn.BCEWithLogitsLoss(weight=torch.tensor([ratio], device=device, dtype=torch.float))\n",
    "                    for ratio in concept_weights]\n",
    "else:\n",
    "    attr_criterion = [nn.BCEWithLogitsLoss() for _ in range(N_TRIMMED_CONCEPTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c567dd5-545b-4d38-ab3c-3a19a028a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs_as_array(outputs, n_concepts):\n",
    "    # Initialize an empty list to collect batches\n",
    "    batch_results = []\n",
    "\n",
    "    for i in range(len(outputs)):\n",
    "        batch_size = outputs[i].shape[0]\n",
    "\n",
    "        # Create a batch matrix with N_CONCEPTS number of columns\n",
    "        batch_matrix = np.zeros((batch_size, n_concepts))\n",
    "\n",
    "        for instance_idx in range(batch_size):\n",
    "            # Extract, convert, and flatten data for the current concept\n",
    "            instance_data = outputs[i][instance_idx].detach().cpu().numpy().flatten()\n",
    "            batch_matrix[instance_idx, :] = instance_data\n",
    "\n",
    "        # Add this consistently shaped batch matrix to our collection\n",
    "        batch_results.append(batch_matrix)\n",
    "\n",
    "    return np.vstack(batch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7dda06",
   "metadata": {},
   "source": [
    "# Load instance-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61fd0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(os.path.join(PROJECT_ROOT, 'models', 'CUB', 'instance_level_model.pth'), map_location=device, weights_only=False)\n",
    "# # model = torch.load(os.path.join(PROJECT_ROOT, 'notebook', 'x_to_c_best_model.pth'), map_location=device, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e7b3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(loader, split_name):\n",
    "    if loader:\n",
    "        with torch.no_grad():\n",
    "            shuffled_concept_labels = []\n",
    "            shuffled_img_labels = []\n",
    "\n",
    "            # Iterate through all batches\n",
    "            for batch in loader:\n",
    "                _, concept_labels, image_labels, _ = batch\n",
    "                # Append batch labels to our list\n",
    "                shuffled_concept_labels.append(concept_labels)\n",
    "                shuffled_img_labels.append(image_labels)\n",
    "\n",
    "            # Concatenate all batches into a single tensor\n",
    "            shuffled_concept_labels = torch.cat(shuffled_concept_labels, dim=0)\n",
    "            shuffled_img_labels = torch.cat(shuffled_img_labels, dim=0)\n",
    "\n",
    "            test_loss, test_acc, outputs = run_epoch_x_to_c(\n",
    "                model, loader, attr_criterion, optimizer=None, n_concepts=N_TRIMMED_CONCEPTS, device=device,\n",
    "                return_outputs='sigmoid', verbose=True\n",
    "            )\n",
    "\n",
    "    # print(f\"Shuffled labels shape: {shuffled_img_labels.shape}\")\n",
    "    output_dir = os.path.join(PROJECT_ROOT, 'output', 'CUB')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    np.save(os.path.join(output_dir, f'C_{split_name}_instance.npy'), shuffled_concept_labels)\n",
    "    np.save(os.path.join(output_dir, f'Y_{split_name}_instance.npy'), shuffled_img_labels)\n",
    "    print(f'Best Model Summary   | Loss: {test_loss:.4f} | Acc: {test_acc:.3f}')\n",
    "\n",
    "    output_array = get_outputs_as_array(outputs, N_TRIMMED_CONCEPTS)\n",
    "    print(f\"Final shape: {output_array.shape}\")\n",
    "\n",
    "    np.save(os.path.join(output_dir, f'C_hat_sigmoid_{split_name}_instance.npy'), output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "912b1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_outputs(train_loader, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b2583f",
   "metadata": {},
   "source": [
    "# LOAD BEST MODEL FROM CBM PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c083c6d8-25bb-4662-b9f2-ec6f58152941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pb/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/serialization.py:1580: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/pb/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/serialization.py:1580: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/pb/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/serialization.py:1580: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/pb/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/serialization.py:1580: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded.\n"
     ]
    }
   ],
   "source": [
    "best_model = os.path.join(PROJECT_ROOT, 'models', 'CUB', 'best_model_1.pth')\n",
    "model = torch.load(best_model, map_location=device, weights_only=False)\n",
    "print(\"Best model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c8a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Summary   | Loss: 11.4714 | Acc: 97.410\n",
      "Final shape: (5994, 112)\n"
     ]
    }
   ],
   "source": [
    "get_outputs(train_loader, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a7f4c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Summary   | Loss: 11.6737 | Acc: 94.864\n",
      "Final shape: (5794, 112)\n"
     ]
    }
   ],
   "source": [
    "get_outputs(test_loader, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b2f509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = os.path.join(PROJECT_ROOT, 'models', 'CUB', 'best_model_2.pth')\n",
    "# get_outputs(train_loader, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "274dc49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = os.path.join(PROJECT_ROOT, 'models', 'CUB', 'best_model_3.pth')\n",
    "# get_outputs(train_loader, 'train')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
