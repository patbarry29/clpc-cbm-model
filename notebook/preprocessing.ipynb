{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70429337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root_path = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, project_root_path)\n",
    "\n",
    "from config import PROJECT_ROOT\n",
    "\n",
    "from src.preprocessing import *\n",
    "from src.utils import get_filename_to_id_mapping\n",
    "from src.dataset import ImageConceptDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaefdc7",
   "metadata": {},
   "source": [
    "## 1. Transform Images to Tensors\n",
    "Convert each image to a tensor of shape - (3, 299, 299).\n",
    "All tensors are stored in a list to improve efficiency. \n",
    "- tensors and np arrays require a single, contiguous block of memory\n",
    "- would be > 12GB with all of our image tensors (all in ram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffab0a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11788 images.\n",
      "Processing in 369 batches of size 32 (for progress reporting)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 369/369 [02:11<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished processing.\n",
      "Successfully transformed: 11788 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND TRANSFORM IMAGES\n",
    "input_dir = os.path.join(PROJECT_ROOT, 'images')\n",
    "resol = 299\n",
    "training = True\n",
    "images_file = os.path.join(PROJECT_ROOT, 'data', 'images.txt')\n",
    "\n",
    "image_tensors, image_paths = load_and_transform_images(input_dir, images_file, resol, training, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2b8f6",
   "metadata": {},
   "source": [
    "## 2. Generate concept label and image label matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289158f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11788 unique images.\n",
      "Found 312 unique concepts.\n",
      "Generated concept matrix with shape: (11788, 312)\n"
     ]
    }
   ],
   "source": [
    "# CREATE CONCEPT LABELS MATRIX\n",
    "concept_labels_file = os.path.join(PROJECT_ROOT, 'data', 'image_concept_labels.txt')\n",
    "\n",
    "concept_labels, uncertainty_matrix = encode_image_concepts(concept_labels_file, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c1461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 classes.\n",
      "Found labels for 11788 images.\n",
      "Generated one-hot matrix with shape: (11788, 200)\n"
     ]
    }
   ],
   "source": [
    "# CREATE IMAGE LABELS MATRIX\n",
    "labels_file = os.path.join(PROJECT_ROOT, 'data', 'image_class_labels.txt')\n",
    "classes_file = os.path.join(PROJECT_ROOT, 'data', 'classes.txt')\n",
    "\n",
    "image_labels = one_hot_encode_labels(labels_file, classes_file, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e14842ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.10737397005211732)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((uncertainty_matrix == 1)&(concept_labels==0))/(uncertainty_matrix.shape[0]*uncertainty_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cebe0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. (Optional) Get image_id->filename mapping.\n",
    "Allows us to check that tensors and label matrices have the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab54760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET IMAGE ID TO IMAGE FILENAME MAPPING\n",
    "images_file = os.path.join(PROJECT_ROOT, 'data', 'images.txt')\n",
    "image_id_mapping = get_filename_to_id_mapping(images_file, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a941d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename of image 4242: \n",
      "\t073.Blue_Jay/Blue_Jay_0002_62657.jpg\n",
      "Image 4242 has concepts: \n",
      "\t[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "Tensor index of image 4242: \n",
      "\t4242\n",
      "Shape of the first tensor: \n",
      "\ttorch.Size([3, 299, 299])\n"
     ]
    }
   ],
   "source": [
    "i = 4242\n",
    "print(f'Filename of image {i}: \\n\\t{image_id_mapping[i]}')\n",
    "print(f\"Image {i} has concepts: \\n\\t{concept_labels[i]}\")\n",
    "\n",
    "image_idx = image_paths.index(image_id_mapping[i])\n",
    "tensor = image_tensors[image_paths.index(image_id_mapping[i])]\n",
    "\n",
    "print(f\"Tensor index of image {i}: \\n\\t{image_idx}\")\n",
    "print(f\"Shape of the first tensor: \\n\\t{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab9a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor index 10 has filename: \n",
      "\t001.Black_footed_Albatross/Black_Footed_Albatross_0023_796059.jpg\n",
      "Filename 001.Black_footed_Albatross/Black_Footed_Albatross_0023_796059.jpg has index: \n",
      "\t10\n"
     ]
    }
   ],
   "source": [
    "i=10\n",
    "\n",
    "image_name = image_paths[i]\n",
    "tensor = image_tensors[i]\n",
    "\n",
    "print(f\"Tensor index {i} has filename: \\n\\t{image_name}\")\n",
    "\n",
    "print(f\"Filename {image_name} has index: \\n\\t{list(image_id_mapping.values()).index(image_name)}\")\n",
    "# print(concept_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e7af5",
   "metadata": {},
   "source": [
    "## 4. Create Train Test Splits using `train_test_split.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd789f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete: 5994 train images, 5794 test images.\n",
      "Train set size: 5994 tensors, 5994 concepts, 5994 labels\n",
      "Test set size:  5794 tensors, 5794 concepts, 5794 labels\n"
     ]
    }
   ],
   "source": [
    "# CREATE TRAIN TEST SPLIT USING TXT FILE\n",
    "split_file = os.path.join(PROJECT_ROOT, 'data', 'train_test_split.txt')\n",
    "\n",
    "split_data = split_datasets(split_file, concept_labels, image_labels, uncertainty_matrix, image_tensors)\n",
    "\n",
    "train_concept_labels = split_data['train_concepts']\n",
    "test_concept_labels = split_data['test_concepts']\n",
    "\n",
    "train_img_labels = split_data['train_img_labels']\n",
    "test_img_labels = split_data['test_img_labels']\n",
    "\n",
    "train_uncertainty = split_data['train_uncertainty']\n",
    "\n",
    "train_tensors = split_data['train_tensors']\n",
    "test_tensors = split_data['test_tensors']\n",
    "\n",
    "print(f\"Train set size: {len(train_tensors)} tensors, {train_concept_labels.shape[0]} concepts, {train_img_labels.shape[0]} labels\")\n",
    "print(f\"Test set size:  {len(test_tensors)} tensors, {test_concept_labels.shape[0]} concepts, {test_img_labels.shape[0]} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8d9d84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 8 9 9 9 9]\n",
      "Selected 109 common concept indices.\n"
     ]
    }
   ],
   "source": [
    "class_level_concepts = compute_class_level_concepts(train_concept_labels, train_uncertainty, train_img_labels)\n",
    "\n",
    "common_concept_indices = select_common_concepts(class_level_concepts, min_class_count=10)\n",
    "\n",
    "print(f\"Selected {len(common_concept_indices)} common concept indices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af86ee77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{225, 99, 198, 309, 152, 125}\n",
      "{np.int64(104), np.int64(173), np.int64(182)}\n",
      "{np.int64(1), np.int64(4), np.int64(6), np.int64(7), np.int64(10), np.int64(14), np.int64(15), np.int64(20), np.int64(21), np.int64(23), np.int64(25), np.int64(29), np.int64(30), np.int64(35), np.int64(36), np.int64(38), np.int64(40), np.int64(44), np.int64(45), np.int64(50), np.int64(51), np.int64(53), np.int64(54), np.int64(56), np.int64(57), np.int64(59), np.int64(63), np.int64(64), np.int64(69), np.int64(70), np.int64(72), np.int64(75), np.int64(80), np.int64(84), np.int64(90), np.int64(91), np.int64(93), np.int64(101), np.int64(104), np.int64(106), np.int64(110), np.int64(111), np.int64(116), np.int64(117), np.int64(119), np.int64(126), np.int64(131), np.int64(132), np.int64(134), np.int64(145), np.int64(149), np.int64(151), np.int64(153), np.int64(157), np.int64(158), np.int64(163), np.int64(164), np.int64(168), np.int64(172), np.int64(173), np.int64(178), np.int64(179), np.int64(181), np.int64(182), np.int64(183), np.int64(187), np.int64(188), np.int64(193), np.int64(194), np.int64(196), np.int64(202), np.int64(203), np.int64(208), np.int64(209), np.int64(211), np.int64(212), np.int64(213), np.int64(218), np.int64(220), np.int64(221), np.int64(235), np.int64(236), np.int64(238), np.int64(239), np.int64(240), np.int64(242), np.int64(243), np.int64(244), np.int64(249), np.int64(253), np.int64(254), np.int64(259), np.int64(260), np.int64(262), np.int64(268), np.int64(274), np.int64(277), np.int64(283), np.int64(289), np.int64(292), np.int64(293), np.int64(294), np.int64(298), np.int64(299), np.int64(304), np.int64(305), np.int64(308), np.int64(310), np.int64(311)}\n"
     ]
    }
   ],
   "source": [
    "theirs = set([1, 4, 6, 7, 10, 14, 15, 20, 21, 23, 25, 29, 30, 35, 36, 38, 40, 44, 45, 50, 51, 53, 54, 56, 57, 59, 63, 64, 69, 70, 72, 75, 80, 84, 90, 91, \\\n",
    "    93, 99, 101, 106, 110, 111, 116, 117, 119, 125, 126, 131, 132, 134, 145, 149, 151, 152, 153, 157, 158, 163, 164, 168, 172, 178, 179, 181, \\\n",
    "    183, 187, 188, 193, 194, 196, 198, 202, 203, 208, 209, 211, 212, 213, 218, 220, 221, 225, 235, 236, 238, 239, 240, 242, 243, 244, 249, 253, \\\n",
    "    254, 259, 260, 262, 268, 274, 277, 283, 289, 292, 293, 294, 298, 299, 304, 305, 308, 309, 310, 311])\n",
    "mine = set(common_concept_indices.astype(int))\n",
    "\n",
    "print(theirs - mine) # 225, 99, 198, 309, 152, 125\n",
    "print(mine-theirs) # 104, 173, 182\n",
    "print(mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3a7470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered instance concepts shape: (5994, 109)\n",
      "Filtered instance concepts shape: (5794, 109)\n"
     ]
    }
   ],
   "source": [
    "train_concept_labels = train_concept_labels[:, common_concept_indices]\n",
    "print(f\"Filtered instance concepts shape: {train_concept_labels.shape}\")\n",
    "test_concept_labels = test_concept_labels[:, common_concept_indices]\n",
    "print(f\"Filtered instance concepts shape: {test_concept_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20caff93",
   "metadata": {},
   "source": [
    "## 5. Create Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cfcf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with 5994 pre-sorted items.\n",
      "Train dataset length: 5994\n",
      "Dataset initialized with 5794 pre-sorted items.\n",
      "Test dataset length: 5794\n"
     ]
    }
   ],
   "source": [
    "full_train_dataset = ImageConceptDataset(\n",
    "    image_tensors=train_tensors,\n",
    "    concept_labels=train_concept_labels,\n",
    "    image_labels=train_img_labels\n",
    ")\n",
    "print(f\"Train dataset length: {len(full_train_dataset)}\")\n",
    "\n",
    "test_dataset = ImageConceptDataset(\n",
    "    image_tensors=test_tensors,\n",
    "    concept_labels=test_concept_labels,\n",
    "    image_labels=test_img_labels\n",
    ")\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab83353",
   "metadata": {},
   "source": [
    "**get validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b77a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proportion = 0.20\n",
    "all_indices = list(range(len(full_train_dataset)))\n",
    "# Assuming you can get all class labels for the training set\n",
    "all_train_labels = full_train_dataset.get_labels()\n",
    "\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    all_indices,\n",
    "    all_train_labels,\n",
    "    test_size=val_proportion,\n",
    "    random_state=42, # for reproducibility\n",
    "    stratify=all_train_labels\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_train_dataset, train_indices)\n",
    "val_dataset = Subset(full_train_dataset, val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb500ea",
   "metadata": {},
   "source": [
    "**Test __getitem__**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1fab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item at index 10:\n",
      "\tImage Tensor Shape: torch.Size([3, 299, 299])\n",
      "\tConcept Labels Shape: torch.Size([312])\n",
      "\tImage Label Shape: torch.Size([200])\n",
      "\n",
      "\tConcept vector (first 10): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\tHas 34.0 true concepts\n",
      "\tHas concepts: ['has_bill_shape::cone', 'has_wing_color::brown', 'has_wing_color::buff', 'has_upperparts_color::brown', 'has_upperparts_color::buff', 'has_underparts_color::grey', 'has_breast_pattern::solid', 'has_back_color::brown', 'has_back_color::buff', 'has_tail_shape::notched_tail', 'has_upper_tail_color::brown', 'has_upper_tail_color::buff', 'has_head_pattern::eyeline', 'has_breast_color::grey', 'has_throat_color::white', 'has_eye_color::black', 'has_bill_length::shorter_than_head', 'has_forehead_color::grey', 'has_under_tail_color::brown', 'has_under_tail_color::buff', 'has_nape_color::grey', 'has_nape_color::black', 'has_belly_color::grey', 'has_size::very_small_(3_-_5_in)', 'has_shape::perching-like', 'has_back_pattern::striped', 'has_tail_pattern::striped', 'has_belly_pattern::solid', 'has_primary_color::brown', 'has_primary_color::grey', 'has_leg_color::buff', 'has_bill_color::black', 'has_crown_color::brown', 'has_wing_pattern::striped']\n",
      "\n",
      "\tImage Class: 130\n"
     ]
    }
   ],
   "source": [
    "concept_names_path = os.path.join(PROJECT_ROOT, 'data', 'concepts.txt')\n",
    "image_id_mapping = get_filename_to_id_mapping(images_file, reverse=True)\n",
    "\n",
    "item_index = 10\n",
    "if item_index < len(train_dataset):\n",
    "    img_tensor, concepts, img_label, img_id = train_dataset[item_index]\n",
    "    print(f\"Item at index {item_index}:\")\n",
    "    print(f\"\\tImage Tensor Shape: {img_tensor.shape}\")\n",
    "    print(f\"\\tConcept Labels Shape: {concepts.shape}\")\n",
    "    print(f\"\\tImage Label Shape: {img_label.shape}\\n\")\n",
    "\n",
    "    # print(f\"\\tImage ID: {img_id}\")\n",
    "    # print(f\"\\tFilename (lookup): {image_id_mapping.get(img_id)}\\n\")\n",
    "\n",
    "    print(f\"\\tConcept vector (first 10): {concepts[:10].numpy()}\")\n",
    "    print(f\"\\tHas {concepts.numpy().sum()} true concepts\")\n",
    "    print(f\"\\tHas concepts: {get_concepts(concepts.numpy(), concept_names_path)}\\n\")\n",
    "\n",
    "    print(f\"\\tImage Class: {np.argmax(img_label.numpy())+1}\")\n",
    "else:\n",
    "    print(f\"Index {item_index} is out of bounds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14b8fb",
   "metadata": {},
   "source": [
    "## 5. Create Train and Test DataLoaders\n",
    "These allow us to generate batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11eb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created with batch size 32.\n",
      "Validation DataLoader created with batch size 32.\n",
      "Test DataLoader created with batch size 32.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# Shuffle training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "print(f\"Train DataLoader created with batch size {batch_size}.\")\n",
    "# Do NOT shuffle val or test data\n",
    "#   pin_memory optimises data transfer from CPU to GPU\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n",
    "print(f\"Validation DataLoader created with batch size {batch_size}.\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n",
    "print(f\"Test DataLoader created with batch size {batch_size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d55de2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get one batch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (batch_tensors, batch_concepts, batch_labels, batch_ids) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mTensor Batch Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_tensors.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/utils/data/dataloader.py:491\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/utils/data/dataloader.py:422\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    421\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1146\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1139\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1144\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1145\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1148\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/context.py:288\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/popen_spawn_posix.py:47\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     46\u001b[39m     reduction.dump(prep_data, fp)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     49\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/multiprocessing/reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:607\u001b[39m, in \u001b[36mreduce_storage\u001b[39m\u001b[34m(storage)\u001b[39m\n\u001b[32m    603\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    604\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot pickle meta storage; try pickling a meta tensor instead\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     )\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m get_sharing_strategy() == \u001b[33m\"\u001b[39m\u001b[33mfile_system\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     metadata = \u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_share_filename_cpu_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m     cache_key = metadata[\u001b[32m1\u001b[39m]\n\u001b[32m    609\u001b[39m     rebuild = rebuild_storage_filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/storage.py:450\u001b[39m, in \u001b[36m_share_memory_lock_protected.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    452\u001b[39m     \u001b[38;5;66;03m# If we acquired the storage lock here and we're done working on it\u001b[39;00m\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# we can now release it and free the entry.\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m to_free \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    455\u001b[39m         \u001b[38;5;66;03m# Ensure that the cdata from the storage didn't change and only\u001b[39;00m\n\u001b[32m    456\u001b[39m         \u001b[38;5;66;03m# the data_ptr did.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/storage.py:529\u001b[39m, in \u001b[36mUntypedStorage._share_filename_cpu_\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;129m@_share_memory_lock_protected\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_share_filename_cpu_\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_share_filename_cpu_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Get one batch\n",
    "for batch_idx, (batch_tensors, batch_concepts, batch_labels, batch_ids) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"\\tTensor Batch Shape: {batch_tensors.shape}\")\n",
    "    print(f\"\\tConcepts Batch Shape: {batch_concepts.shape}\")\n",
    "    print(f\"\\tLabels Batch Shape: {batch_labels.shape}\")\n",
    "    print(f\"\\tBatch IDs: {batch_ids}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899438ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
