{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70429337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root_path = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, project_root_path)\n",
    "\n",
    "from config import PROJECT_ROOT\n",
    "\n",
    "from src.preprocessing import *\n",
    "from src.utils import get_filename_to_id_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaefdc7",
   "metadata": {},
   "source": [
    "## 1. Transform Images to Tensors\n",
    "Convert each image to a tensor of shape - (3, 299,299).\n",
    "All tensors are stored in a list to improve efficiency. \n",
    "- tensors and np arrays require a single, contiguous block of memory\n",
    "- would be > 12GB with all of our image tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffab0a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TRAINING transformations:\n",
      "Found 11788 images.\n",
      "Processing in 369 batches of size 32 (for progress reporting)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 369/369 [01:02<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished processing.\n",
      "Successfully transformed: 11788 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND TRANSFORM IMAGES\n",
    "input_dir = os.path.join(PROJECT_ROOT, 'images')\n",
    "resol = 299\n",
    "training = True\n",
    "images_file = os.path.join(PROJECT_ROOT, 'data', 'images.txt')\n",
    "\n",
    "image_tensors, image_paths = load_and_transform_images(input_dir, images_file, resol, training, batch_size=32, verbose=True, dev=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2b8f6",
   "metadata": {},
   "source": [
    "## 2. Generate concept label and image label matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289158f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11788 unique images.\n",
      "Found 312 unique concepts.\n",
      "Generated concept matrix with shape: (11788, 312)\n"
     ]
    }
   ],
   "source": [
    "# CREATE CONCEPT LABELS MATRIX\n",
    "concept_labels_file = os.path.join(PROJECT_ROOT, 'data', 'image_concept_labels.txt')\n",
    "\n",
    "concept_labels = encode_image_concepts(concept_labels_file, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c1461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 classes.\n",
      "Found labels for 11788 images.\n",
      "Generated one-hot matrix with shape: (11788, 200)\n"
     ]
    }
   ],
   "source": [
    "# CREATE IMAGE LABELS MATRIX\n",
    "labels_file = os.path.join(PROJECT_ROOT, 'data', 'image_class_labels.txt')\n",
    "classes_file = os.path.join(PROJECT_ROOT, 'data', 'classes.txt')\n",
    "\n",
    "image_labels = one_hot_encode_labels(labels_file, classes_file, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cebe0c",
   "metadata": {},
   "source": [
    "## 3. (Optional) Get image_id->filename mapping.\n",
    "Allows us to check that tensors and label matrices have the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab54760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET IMAGE ID TO IMAGE FILENAME MAPPING\n",
    "images_file = os.path.join(PROJECT_ROOT, 'data', 'images.txt')\n",
    "image_id_mapping = get_filename_to_id_mapping(images_file, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a941d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename of image 4242: \n",
      "\t073.Blue_Jay/Blue_Jay_0002_62657.jpg\n",
      "Image 4242 has concepts: \n",
      "\t[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "Tensor index of image 4242: \n",
      "\t4242\n",
      "Shape of the first tensor: \n",
      "\ttorch.Size([3, 299, 299])\n"
     ]
    }
   ],
   "source": [
    "i = 4242\n",
    "print(f'Filename of image {i}: \\n\\t{image_id_mapping[i]}')\n",
    "print(f\"Image {i} has concepts: \\n\\t{concept_labels[i]}\")\n",
    "\n",
    "image_idx = image_paths.index(image_id_mapping[i])\n",
    "tensor = image_tensors[image_paths.index(image_id_mapping[i])]\n",
    "\n",
    "print(f\"Tensor index of image {i}: \\n\\t{image_idx}\")\n",
    "print(f\"Shape of the first tensor: \\n\\t{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab9a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor index 10 has filename: \n",
      "\t001.Black_footed_Albatross/Black_Footed_Albatross_0023_796059.jpg\n",
      "Filename 001.Black_footed_Albatross/Black_Footed_Albatross_0023_796059.jpg has index: \n",
      "\t10\n"
     ]
    }
   ],
   "source": [
    "i=10\n",
    "\n",
    "image_name = image_paths[i]\n",
    "tensor = image_tensors[i]\n",
    "\n",
    "print(f\"Tensor index {i} has filename: \\n\\t{image_name}\")\n",
    "\n",
    "print(f\"Filename {image_name} has index: \\n\\t{list(image_id_mapping.values()).index(image_name)}\")\n",
    "# print(concept_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e7af5",
   "metadata": {},
   "source": [
    "## 4. Create Train Test Splits using `train_test_split.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd789f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete: 5994 train images, 5794 test images.\n",
      "Train set size: 5994 tensors, 5994 concepts, 5994 labels\n",
      "Test set size:  5794 tensors, 5794 concepts, 5794 labels\n"
     ]
    }
   ],
   "source": [
    "# CREATE TRAIN TEST SPLIT USING TXT FILE\n",
    "split_file = os.path.join(PROJECT_ROOT, 'data', 'train_test_split.txt')\n",
    "\n",
    "split_data = split_datasets(split_file, concept_labels, image_labels, image_tensors)\n",
    "\n",
    "train_concepts = split_data['train_concepts']\n",
    "test_concepts = split_data['test_concepts']\n",
    "\n",
    "train_img_labels = split_data['train_img_labels']\n",
    "test_img_labels = split_data['test_img_labels']\n",
    "\n",
    "train_tensors = split_data['train_tensors']\n",
    "test_tensors = split_data['test_tensors']\n",
    "\n",
    "print(f\"Train set size: {len(train_tensors)} tensors, {train_concepts.shape[0]} concepts, {train_img_labels.shape[0]} labels\")\n",
    "print(f\"Test set size:  {len(test_tensors)} tensors, {test_concepts.shape[0]} concepts, {test_img_labels.shape[0]} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20caff93",
   "metadata": {},
   "source": [
    "## 5. Create Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81cfcf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Datasets ---\n",
      "Dataset initialized with 5994 pre-sorted items.\n",
      "Train dataset length: 5994\n",
      "Dataset initialized with 5794 pre-sorted items.\n",
      "Test dataset length: 5794\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import ImageConceptDataset\n",
    "print(\"\\n--- Creating Datasets ---\")\n",
    "train_dataset = ImageConceptDataset(\n",
    "    image_tensors=train_tensors,\n",
    "    concept_labels=train_concepts,\n",
    "    image_labels=train_img_labels\n",
    ")\n",
    "print(f\"Train dataset length: {len(train_dataset)}\")\n",
    "\n",
    "test_dataset = ImageConceptDataset(\n",
    "    image_tensors=test_tensors,\n",
    "    concept_labels=test_concepts,\n",
    "    image_labels=test_img_labels\n",
    ")\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c1fab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item at index 10:\n",
      "\tImage Tensor Shape: torch.Size([3, 299, 299])\n",
      "\tConcept Labels Shape: torch.Size([312])\n",
      "\tImage Label Shape: torch.Size([200])\n",
      "\n",
      "\tImage ID: 11\n",
      "\tFilename (lookup): 001.Black_footed_Albatross/Black_Footed_Albatross_0086_796062.jpg\n",
      "\n",
      "\tConcept vector (first 10): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\tHas 22.0 true concepts\n",
      "\tHas concepts: ['has_bill_shape::hooked_seabird', 'has_wing_color::black', 'has_upperparts_color::black', 'has_breast_pattern::solid', 'has_back_color::black', 'has_upper_tail_color::black', 'has_head_pattern::eyeline', 'has_breast_color::grey', 'has_throat_color::black', 'has_eye_color::black', 'has_bill_length::about_the_same_as_head', 'has_forehead_color::grey', 'has_under_tail_color::black', 'has_nape_color::grey', 'has_size::medium_(9_-_16_in)', 'has_shape::duck-like', 'has_back_pattern::solid', 'has_tail_pattern::solid', 'has_primary_color::black', 'has_bill_color::grey', 'has_crown_color::grey', 'has_wing_pattern::solid']\n",
      "\n",
      "\tImage Class: 1\n"
     ]
    }
   ],
   "source": [
    "# --- Test __getitem__ ---\n",
    "concept_names_path = os.path.join(PROJECT_ROOT, 'data', 'concepts.txt')\n",
    "\n",
    "item_index = 10\n",
    "if item_index < len(train_dataset):\n",
    "    img_tensor, concepts, img_label, img_id = train_dataset[item_index]\n",
    "    print(f\"Item at index {item_index}:\")\n",
    "    print(f\"\\tImage Tensor Shape: {img_tensor.shape}\")\n",
    "    print(f\"\\tConcept Labels Shape: {concepts.shape}\")\n",
    "    print(f\"\\tImage Label Shape: {img_label.shape}\\n\")\n",
    "\n",
    "    print(f\"\\tImage ID: {img_id}\")\n",
    "    print(f\"\\tFilename (lookup): {image_id_mapping.get(img_id)}\\n\")\n",
    "\n",
    "    print(f\"\\tConcept vector (first 10): {concepts[:10].numpy()}\")\n",
    "    print(f\"\\tHas {concepts.numpy().sum()} true concepts\")\n",
    "    print(f\"\\tHas concepts: {get_concepts(concepts.numpy(), concept_names_path)}\\n\")\n",
    "\n",
    "    print(f\"\\tImage Class: {np.argmax(img_label.numpy())+1}\")\n",
    "else:\n",
    "    print(f\"Index {item_index} is out of bounds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14b8fb",
   "metadata": {},
   "source": [
    "## 5. Create Train and Test DataLoaders\n",
    "These allow us to generate batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd11eb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating DataLoaders ---\n",
      "Train DataLoader created with batch size 32.\n",
      "Test DataLoader created with batch size 32.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "print(\"\\n--- Creating DataLoaders ---\")\n",
    "# Shuffle training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# Do NOT shuffle test data - usually evaluate in order\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "print(f\"Train DataLoader created with batch size {batch_size}.\")\n",
    "print(f\"Test DataLoader created with batch size {batch_size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d55de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "\tTensor Batch Shape: torch.Size([32, 3, 299, 299])\n",
      "\tConcepts Batch Shape: torch.Size([32, 312])\n",
      "\tLabels Batch Shape: torch.Size([32, 200])\n",
      "\tBatch IDs: tensor([2164, 3313, 1355, 3610,  629, 3327, 5402,  857, 4007, 5432, 2211, 4080,\n",
      "        2823, 5452, 2290, 2743, 5109,   42, 2577, 4940, 1061, 3900, 4603,  651,\n",
      "        5260, 5354, 3196, 1505,  821,  366, 5468, 1210])\n"
     ]
    }
   ],
   "source": [
    "# Get one batch\n",
    "for batch_idx, (batch_tensors, batch_concepts, batch_labels, batch_ids) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"\\tTensor Batch Shape: {batch_tensors.shape}\")\n",
    "    print(f\"\\tConcepts Batch Shape: {batch_concepts.shape}\")\n",
    "    print(f\"\\tLabels Batch Shape: {batch_labels.shape}\")\n",
    "    print(f\"\\tBatch IDs: {batch_ids}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155acf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
