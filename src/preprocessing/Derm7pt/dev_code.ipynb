{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "PROJECT_ROOT = os.path.abspath(\"../../../\")\n",
    "\n",
    "from derm7pt.dataset import Derm7PtDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images = os.path.join(PROJECT_ROOT, 'images', 'Derm7pt')\n",
    "dir_data = os.path.join(PROJECT_ROOT, 'data', 'Derm7pt')\n",
    "\n",
    "path_meta_csv = os.path.join(dir_data, 'meta.csv')\n",
    "path_train_idx_csv = os.path.join(dir_data, 'train_indexes.csv')\n",
    "path_valid_idx_csv = os.path.join(dir_data, 'valid_indexes.csv')\n",
    "path_test_idx_csv = os.path.join(dir_data, 'test_indexes.csv')\n",
    "\n",
    "metadata_df_original = pd.read_csv(path_meta_csv)\n",
    "\n",
    "train_indexes = list(pd.read_csv(path_train_idx_csv)['indexes'])\n",
    "valid_indexes = list(pd.read_csv(path_valid_idx_csv)['indexes'])\n",
    "test_indexes = list(pd.read_csv(path_test_idx_csv)['indexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For granular labels:\n",
    "dataset_handler = Derm7PtDataset(\n",
    "    dir_images=dir_images,\n",
    "    metadata_df=metadata_df_original.copy(), # Pass a copy as the class modifies it\n",
    "    train_indexes=train_indexes,\n",
    "    valid_indexes=valid_indexes,\n",
    "    test_indexes=test_indexes\n",
    ")\n",
    "\n",
    "print(\"\\nDataset handler initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows of the processed DataFrame:\")\n",
    "print(dataset_handler.df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1078d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nColumns in the processed DataFrame:\")\n",
    "print(dataset_handler.df.columns)\n",
    "# You'll see original columns and new '_numeric' columns\n",
    "# e.g., 'diagnosis' and 'diagnosis_numeric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_handler.dataset_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAvailable tags (categories of concepts):\")\n",
    "print(dataset_handler.tags) # Shows 'DIAG', 'PN', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dfabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_labels_numeric = dataset_handler.get_labels(data_type='all', one_hot=False)['DIAG']\n",
    "print(f\"\\nNumeric labels for 'DIAG' (Diagnosis) for all images (first 10): \\n{diag_labels_numeric.head(10)}\")\n",
    "\n",
    "diag_labels_one_hot = dataset_handler.get_labels(data_type='all', one_hot=True)['DIAG']\n",
    "print(f\"\\nOne-hot encoded labels for 'DIAG' for all images (first 5 rows): \\n{diag_labels_one_hot[:5]}\")\n",
    "\n",
    "# To understand what the numeric/one-hot labels mean:\n",
    "diagnosis_definitions = dataset_handler.get_label_by_abbrev('DIAG')\n",
    "print(f\"\\nDefinitions for 'DIAG' labels: \\n{diagnosis_definitions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a70eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "\n",
    "image_derm = dataset_handler.derm_image(row_index=idx) # Loads image for the first row in the df\n",
    "print(f\"\\nShape (size) of dermoscopic image {idx}: {image_derm.shape}\")\n",
    "# You can use matplotlib to display it if you're in an environment that supports it\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(image_derm)\n",
    "# plt.title(\"Dermoscopic Image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815be4c",
   "metadata": {},
   "source": [
    "# GET CONCEPT MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = dataset_handler._get_data_frame()\n",
    "all_data = dataset_handler.get_labels(data_type='all', one_hot=True)\n",
    "\n",
    "Y = all_data['DIAG']\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5319da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize concepts_matrix as an empty array\n",
    "concepts_matrix = None\n",
    "\n",
    "# Loop through the 7 concept categories\n",
    "for i in range(7):\n",
    "    feature_set = list(all_data.values())[i+1]\n",
    "\n",
    "    # For the first iteration, initialize concepts_matrix\n",
    "    if concepts_matrix is None:\n",
    "        concepts_matrix = feature_set\n",
    "    else:\n",
    "        # Concatenate horizontally (along axis 1)\n",
    "        concepts_matrix = np.hstack((concepts_matrix, feature_set))\n",
    "\n",
    "# Check the final shape\n",
    "print(f\"Final concepts_matrix shape: {concepts_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the concepts_matrix creation to ensure we know exactly what we're adding\n",
    "concepts_matrix = None\n",
    "concept_meanings = []\n",
    "\n",
    "# Instead of using numeric indices, explicitly iterate through the tags\n",
    "for tag in dataset_handler.tags.abbrevs:\n",
    "    # if tag == 'DIAG':\n",
    "    #     continue\n",
    "    # Get the one-hot encoded matrix for this tag\n",
    "    feature_set = all_data[tag]\n",
    "\n",
    "    # For the first iteration, initialize concepts_matrix\n",
    "    if concepts_matrix is None:\n",
    "        concepts_matrix = feature_set\n",
    "    else:\n",
    "        # Concatenate horizontally (along axis 1)\n",
    "        concepts_matrix = np.hstack((concepts_matrix, feature_set))\n",
    "\n",
    "    # Get the definitions for this tag\n",
    "    tag_definitions = dataset_handler.get_label_by_abbrev(tag)\n",
    "\n",
    "    # Store the meaning of each column for this tag\n",
    "    num_concepts = feature_set.shape[1]\n",
    "    for i in range(num_concepts):\n",
    "        name = tag_definitions.names[i]\n",
    "\n",
    "        concept_meanings.append((tag, name))\n",
    "\n",
    "# concept_meanings = np.array(concept_meanings)\n",
    "# Verify we have the correct number of mappings\n",
    "print(f\"Total number of concept columns: {concepts_matrix.shape}\")\n",
    "print(f\"Total number of concept meanings: {len(concept_meanings)}\")\n",
    "\n",
    "# Print a few examples to verify\n",
    "for i in range(5):\n",
    "    print(f\"Column {i}: {concept_meanings[i][0]}-{concept_meanings[i][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260396be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concepts_present = np.where(concepts_matrix[0] == 1)[0]\n",
    "\n",
    "# print(concept_meanings[concepts_present])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17481d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0cb57d3",
   "metadata": {},
   "source": [
    "# Image Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d58cc7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_handler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdataset_handler\u001b[49m.df[[\u001b[33m'\u001b[39m\u001b[33mclinic\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mderm\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset_handler' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_handler.df[['clinic', 'derm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3738144d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_handler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m clinic_imgs = \u001b[43mdataset_handler\u001b[49m.df[\u001b[33m'\u001b[39m\u001b[33mclinic\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      2\u001b[39m derm_imgs = dataset_handler.df[\u001b[33m'\u001b[39m\u001b[33mderm\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m case_nums = dataset_handler.df[\u001b[33m'\u001b[39m\u001b[33mcase_num\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset_handler' is not defined"
     ]
    }
   ],
   "source": [
    "clinic_imgs = dataset_handler.df['clinic']\n",
    "derm_imgs = dataset_handler.df['derm']\n",
    "case_nums = dataset_handler.df['case_num']\n",
    "\n",
    "case_images_dict = {\n",
    "    case: {'clinic_img': clinic, 'derm_img': derm}\n",
    "    for case, clinic, derm in zip(case_nums, clinic_imgs, derm_imgs)\n",
    "}\n",
    "\n",
    "# Print a sample to verify\n",
    "print(case_images_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_parts = derm_imgs.str.split('/').str[0].str.upper()\n",
    "\n",
    "# print(np.unique(first_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c776f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fafa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.Derm7pt import export_image_props_to_text\n",
    "\n",
    "export_image_props_to_text(dataset_handler.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70563d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.Derm7pt import preprocessing_main\n",
    "\n",
    "labels = preprocessing_main(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmax(labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e3b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = encode_image_concepts(dataset_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_path = os.path.join(PROJECT_ROOT, 'data', 'Derm7pt', 'image_names.txt')\n",
    "flattened_df = pd.read_csv(image_names_path, sep=' ', header=None, names=['img_id', 'img_path', 'img_type', 'case_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_concepts = []\n",
    "\n",
    "for _, row in flattened_df.iterrows():\n",
    "    case_id = row['case_id']\n",
    "    case_concepts = concepts_matrix[case_id]\n",
    "    all_concepts.append(case_concepts)\n",
    "\n",
    "all_concepts = np.array(all_concepts)\n",
    "all_concepts.shape\n",
    "\n",
    "# flattened_df['concepts'] = all_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75339d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4047531a",
   "metadata": {},
   "source": [
    "# Preprocessing CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.Derm7pt import *\n",
    "from src import ImageConceptDataset\n",
    "from src.preprocessing import *\n",
    "from src.utils import get_paths, load_Derm_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f19f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_paths()\n",
    "dataset_handler = load_Derm_dataset(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d2d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure text files exist\n",
    "if not os.path.exists(paths['labels_file']):\n",
    "    export_image_props_to_text(dataset_handler.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64775fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773d446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 classes.\n",
      "Found labels for 2022 images.\n",
      "Generated one-hot matrix with shape: (2022, 34)\n",
      "Total number of concept columns: 28\n",
      "Found 2013 images.\n",
      "Processing in 63 batches of size 32 (for progress reporting)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 63/63 [00:14<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished processing.\n",
      "Successfully transformed: 2013 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get labels and concepts\n",
    "image_labels = one_hot_encode_labels(paths['labels_file'], paths['classes_path'], verbose=verbose)\n",
    "concepts_matrix = encode_image_concepts(dataset_handler, verbose=verbose)\n",
    "\n",
    "# Load and transform images\n",
    "image_tensors, image_paths = load_and_transform_images(paths['dir_images'], paths['mapping_file'], resol=299, use_training_transforms=True, batch_size=32, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9285754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (2013, 34)\n",
      "Concepts shape: (2013, 28)\n",
      "Image tensors length: 2013\n"
     ]
    }
   ],
   "source": [
    "# Filter if needed\n",
    "if image_labels.shape[0] != len(image_tensors):\n",
    "    filtered_image_labels, filtered_concepts_matrix = filter_concepts_labels(\n",
    "        paths['mapping_file'], image_tensors, image_paths, image_labels, concepts_matrix\n",
    "    )\n",
    "else:\n",
    "    filtered_image_labels, filtered_concepts_matrix = image_labels, concepts_matrix\n",
    "\n",
    "if verbose:\n",
    "    print(\"Labels shape:\", filtered_image_labels.shape)\n",
    "    print(\"Concepts shape:\", filtered_concepts_matrix.shape)\n",
    "    print(\"Image tensors length:\", len(image_tensors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9593a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_dict, concepts_dict, labels_dict = split_data_by_indices(\n",
    "    image_tensors, image_paths, filtered_concepts_matrix, filtered_image_labels,\n",
    "    paths, verbose=verbose\n",
    ")\n",
    "\n",
    "train_concept_labels = concepts_dict['train']\n",
    "val_concept_labels = concepts_dict['val']\n",
    "test_concept_labels = concepts_dict['test']\n",
    "\n",
    "train_img_labels = labels_dict['train']\n",
    "val_img_labels = labels_dict['val']\n",
    "test_img_labels = labels_dict['test']\n",
    "\n",
    "train_tensors = tensors_dict['train']\n",
    "val_tensors = tensors_dict['val']\n",
    "test_tensors = tensors_dict['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f185c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept processing\n",
    "from config import DERM7PT_CONFIG\n",
    "\n",
    "class_level_concepts = compute_class_level_concepts(train_concept_labels, None, train_img_labels)\n",
    "\n",
    "# apply class-level concepts to each instance\n",
    "if True:\n",
    "    train_concept_labels, test_concept_labels = apply_class_concepts_to_instances(train_img_labels, train_concept_labels, class_level_concepts, test_img_labels, test_concept_labels, DERM7PT_CONFIG)\n",
    "\n",
    "common_concept_indices = select_common_concepts(class_level_concepts, min_class_count=2, CUB=False)\n",
    "train_concept_labels = train_concept_labels[:, common_concept_indices]\n",
    "test_concept_labels = test_concept_labels[:, common_concept_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a092bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_concept_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f9f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with 826 pre-sorted items.\n",
      "Dataset initialized with 790 pre-sorted items.\n"
     ]
    }
   ],
   "source": [
    "# CREATE TRAIN AND TEST DATASET\n",
    "train_dataset = ImageConceptDataset(\n",
    "    image_tensors=train_tensors,\n",
    "    concept_labels=train_concept_labels,\n",
    "    image_labels=train_img_labels\n",
    ")\n",
    "\n",
    "test_dataset = ImageConceptDataset(\n",
    "    image_tensors=test_tensors,\n",
    "    concept_labels=test_concept_labels,\n",
    "    image_labels=test_img_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATALOADERS FROM DATASETS\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac42986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
